#!/bin/bash

echo "=========================================="
echo "ðŸ§ª TEST COMPLET AVRO + SCHEMA REGISTRY"
echo "=========================================="

GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m'

# 1. VÃ©rifier Kafka (avec kafka-topics au lieu de curl)
echo -e "\n${YELLOW}ðŸ“‹ Ã‰TAPE 1: VÃ©rification de Kafka${NC}"
if docker exec kafka-earthquake kafka-broker-api-versions --bootstrap-server localhost:9092 &>/dev/null; then
    echo -e "${GREEN}âœ… Kafka est prÃªt!${NC}"
else
    echo -e "${RED}âŒ Kafka ne rÃ©pond pas${NC}"
    echo "DÃ©marrez Kafka avec: docker-compose up -d"
    exit 1
fi

# 2. VÃ©rifier Schema Registry
echo -e "\n${YELLOW}ðŸ“‹ Ã‰TAPE 2: VÃ©rification Schema Registry${NC}"
if curl -s http://localhost:8081/subjects > /dev/null 2>&1; then
    echo -e "${GREEN}âœ… Schema Registry est prÃªt!${NC}"
else
    echo -e "${RED}âŒ Schema Registry ne rÃ©pond pas${NC}"
    exit 1
fi

# 3. VÃ©rifier les topics
echo -e "\n${YELLOW}ðŸ“‹ Ã‰TAPE 3: VÃ©rification des topics${NC}"
if docker exec kafka-earthquake kafka-topics --bootstrap-server localhost:9092 --list | grep -q "data.raw.earthquakes"; then
    echo -e "${GREEN}âœ… Topic data.raw.earthquakes existe${NC}"
else
    echo -e "${YELLOW}âš ï¸  Topic n'existe pas, crÃ©ation...${NC}"
    python3 create_topics_advanced.py
fi

# 4. CrÃ©er le dossier schemas
echo -e "\n${YELLOW}ðŸ“‹ Ã‰TAPE 4: CrÃ©ation des fichiers schÃ©mas${NC}"
mkdir -p schemas

# 5. CrÃ©er les schÃ©mas Avro
echo -e "\n${YELLOW}CrÃ©ation du schÃ©ma RAW...${NC}"
cat > schemas/earthquake_raw.avsc << 'SCHEMA'
{
  "type": "record",
  "name": "EarthquakeRaw",
  "namespace": "com.earthquake.raw",
  "fields": [
    {"name": "event_id", "type": "string"},
    {"name": "timestamp", "type": "long"},
    {"name": "timestamp_updated", "type": ["null", "long"], "default": null},
    {"name": "magnitude", "type": ["null", "double"], "default": null},
    {"name": "magnitude_type", "type": ["null", "string"], "default": null},
    {"name": "location", "type": ["null", "string"], "default": null},
    {"name": "depth_km", "type": ["null", "double"], "default": null},
    {"name": "latitude", "type": ["null", "double"], "default": null},
    {"name": "longitude", "type": ["null", "double"], "default": null},
    {"name": "alert_level", "type": "string", "default": "none"},
    {"name": "felt_reports", "type": ["null", "int"], "default": null},
    {"name": "cdi", "type": ["null", "double"], "default": null},
    {"name": "mmi", "type": ["null", "double"], "default": null},
    {"name": "tsunami", "type": "int", "default": 0},
    {"name": "significance", "type": ["null", "int"], "default": null},
    {"name": "network", "type": ["null", "string"], "default": null},
    {"name": "source", "type": "string"},
    {"name": "ingestion_timestamp", "type": "string"},
    {"name": "api_version", "type": "string"}
  ]
}
SCHEMA

echo -e "${GREEN}âœ… SchÃ©ma RAW crÃ©Ã©${NC}"

echo -e "\n${YELLOW}CrÃ©ation du schÃ©ma CLEANED...${NC}"
cat > schemas/earthquake_cleaned.avsc << 'SCHEMA'
{
  "type": "record",
  "name": "EarthquakeCleaned",
  "namespace": "com.earthquake.cleaned",
  "fields": [
    {"name": "event_id", "type": "string"},
    {"name": "timestamp_utc", "type": "string"},
    {"name": "magnitude", "type": "double"},
    {"name": "severity", "type": "string"},
    {"name": "depth_km", "type": "double"},
    {"name": "depth_category", "type": "string"},
    {"name": "latitude", "type": "double"},
    {"name": "longitude", "type": "double"},
    {"name": "danger_score", "type": "double"},
    {"name": "risk_level", "type": "int"},
    {"name": "processing_timestamp", "type": "string"},
    {"name": "schema_version", "type": "string"}
  ]
}
SCHEMA

echo -e "${GREEN}âœ… SchÃ©ma CLEANED crÃ©Ã©${NC}"

# 6. Enregistrer les schÃ©mas
echo -e "\n${YELLOW}ðŸ“‹ Ã‰TAPE 5: Enregistrement des schÃ©mas${NC}"
python3 register_schemas.py

# 7. VÃ©rifier les schÃ©mas
echo -e "\n${YELLOW}ðŸ“‹ Ã‰TAPE 6: VÃ©rification des schÃ©mas enregistrÃ©s${NC}"
echo "SchÃ©mas disponibles:"
curl -s http://localhost:8081/subjects | python3 -m json.tool

echo -e "\n=========================================="
echo -e "${GREEN}âœ… CONFIGURATION AVRO TERMINÃ‰E!${NC}"
echo "=========================================="
echo ""
echo "ðŸš€ PROCHAINES Ã‰TAPES:"
echo ""
echo "1ï¸âƒ£ Lancer le producer Avro:"
echo "   python3 producer_earthquake_avro.py"
echo ""
echo "2ï¸âƒ£ Dans un autre terminal, vÃ©rifier avec:"
echo "   python3 check_cleaned.py"
echo ""
echo "3ï¸âƒ£ Voir dans Kafka UI:"
echo "   http://localhost:8090"
echo ""
echo "=========================================="
